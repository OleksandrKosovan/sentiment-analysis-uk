{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Функції"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_paragraph(text_corpus):\n",
    "    new_text_corpus = text_corpus.replace('\\n','')\n",
    "    return new_text_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowercase(text_corpus):\n",
    "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\n",
    "    words = text_corpus.split(' ')\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = word.lower()\n",
    "        new_words.append(new_word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text_corpus):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    words = text_corpus.split(' ')\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_numbers(text_corpus):\n",
    "    \"\"\"Replace all interger occurrences in list of tokenized words with textual representation\"\"\"\n",
    "    words = text_corpus.split(' ')\n",
    "    p = inflect.engine()\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word.isdigit():\n",
    "            new_word = p.number_to_words(word)\n",
    "            new_words.append(new_word)\n",
    "        else:\n",
    "            new_words.append(word)\n",
    "    return ' '.join(new_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PATH = \"/Users/oleksandrkosovan/Documents/GitHub/\"\n",
    "LEM_PATH = \"nlp_uk/src/main/groovy/org/nlp_uk/tools/LemmatizeText.groovy\"\n",
    "\n",
    "def lemmatization(\n",
    "    in_data_path, \n",
    "    in_file_name, \n",
    "    out_data_path, \n",
    "    out_file_name, \n",
    "    system_path=SYSTEM_PATH, \n",
    "    lem_path=LEM_PATH\n",
    "):\n",
    "    in_path = os.path.join(in_data_path, in_file_name)\n",
    "    out_path = os.path.join(out_data_path, out_file_name)\n",
    "    \n",
    "    lem_command = \"groovy \" + os.path.join(system_path, lem_path) + \" -i \" + in_path + \" -o \" + out_path\n",
    "    os.system(lem_command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preparation(\n",
    "    in_data_path,\n",
    "    in_file_name,\n",
    "    out_data_path,\n",
    "    out_file_name,\n",
    "):\n",
    "    with open(os.path.join(in_data_path, in_file_name), 'r') as file:\n",
    "        text = file.read()\n",
    "        file.close()\n",
    "    new_text = remove_paragraph(text)\n",
    "    new_text = to_lowercase(new_text)\n",
    "    new_text = remove_punctuation(new_text)\n",
    "    new_text = replace_numbers(new_text)\n",
    "    with open(os.path.join(out_data_path, out_file_name),\"w\") as out_put:\n",
    "        out_put.write(new_text)\n",
    "        out_put.close()\n",
    "    \n",
    "    lemmatization(\n",
    "        in_data_path,\n",
    "        in_file_name,\n",
    "        out_data_path,\n",
    "        out_file_name\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "text_preparation(\n",
    "    in_data_path='',\n",
    "    in_file_name='text.txt',\n",
    "    out_data_path='',\n",
    "    out_file_name='file.txt',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Підготовка тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1923/1923 [00:00<00:00, 37075.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IN_DATA_PATH = 'reviews-data/negative/'\n",
    "OUT_DATA_PATH = 'lem-data/negative/'\n",
    "\n",
    "checking_file_kist = os.listdir(OUT_DATA_PATH)\n",
    "\n",
    "files_list = os.listdir(IN_DATA_PATH)\n",
    "for file in tqdm(files_list):\n",
    "    if file not in checking_file_kist:\n",
    "        try:\n",
    "            text_preparation(\n",
    "                in_data_path=IN_DATA_PATH,\n",
    "                in_file_name=file,\n",
    "                out_data_path=OUT_DATA_PATH,\n",
    "                out_file_name=file,\n",
    "            )\n",
    "        except:\n",
    "            print('some error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1113/1113 [00:00<00:00, 31153.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some error\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "IN_DATA_PATH = 'reviews-data/positive/'\n",
    "OUT_DATA_PATH = 'lem-data/positive/'\n",
    "\n",
    "checking_file_kist = os.listdir(OUT_DATA_PATH)\n",
    "\n",
    "files_list = os.listdir(IN_DATA_PATH)\n",
    "for file in tqdm(files_list):\n",
    "    if file not in checking_file_kist:\n",
    "        try:\n",
    "            text_preparation(\n",
    "                in_data_path=IN_DATA_PATH,\n",
    "                in_file_name=file,\n",
    "                out_data_path=OUT_DATA_PATH,\n",
    "                out_file_name=file,\n",
    "            )\n",
    "        except:\n",
    "            print('some error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
